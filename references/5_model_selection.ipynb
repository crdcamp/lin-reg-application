{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7527fb1b",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "[Resource](https://harvard-iacs.github.io/2018-CS109A/sections/section-4/demo/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec2a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (13.0, 6.0)\n",
    "\n",
    "import itertools\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option(\"display.width\", 500)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba4389",
   "metadata": {},
   "source": [
    "# NYC Car Hire Dataset\n",
    "\n",
    "Welp... here we are again. This data requires a request for access to the professor's google drive, SO it looks like our only current option is to read through the example for now. Who knows! Maybe they'll accept my Google Drive access request!\n",
    "\n",
    "Worst comes to worst, we can just skip right to [the lab](https://harvard-iacs.github.io/2018-CS109A/labs/lab-4/solutions/) with the expectancy that it will show some model selection techniques.\n",
    "\n",
    "Yea.. sounds like a plan! Read through the [model selection](https://harvard-iacs.github.io/2018-CS109A/sections/section-4/demo/) code to get an idea and know what to expect, then move on to [lab 4](https://harvard-iacs.github.io/2018-CS109A/sections/section-4/demo/).\n",
    "\n",
    "While I'm going over the lecture, I'm gonna write down some notes.\n",
    "\n",
    "## Python Set .difference()\n",
    "\n",
    "The first noteworthy takeaway is the `.difference()` method, which can be used to find elements that exist in one set but not in another. It returns a new set containing elements from the first set that are not present in the second set.\n",
    "\n",
    "This operation is similar to the subtraction of sets, where only unique elements from the first set remain. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f220a444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10, 20}\n",
      "{100, 60}\n"
     ]
    }
   ],
   "source": [
    "A = {10, 20, 30, 40, 80}\n",
    "B = {100, 30, 80, 40, 60}\n",
    "\n",
    "print(A.difference(B)) # Elements in A but not in B\n",
    "print(B.difference(A)) # Elements in B but not in A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b259bc",
   "metadata": {},
   "source": [
    "I remember using this once, and it could definitely come in handy later for checking which rows of data have already been processed within a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64133107",
   "metadata": {},
   "source": [
    "# Scaling and Normalization\n",
    "\n",
    "Quick exercise: for which of the following do the units of the predictors matter (e.g., trip length in minutes vs. seconds; temperature in F or C)?\n",
    "\n",
    "* **kNN: Yes.** Scaling affects distance metric, which determines what \"neighbor\" means.\n",
    "* **Linear regression: No.** Multiply predictor by *c* -> divide coefficient by *c*.\n",
    "* **Lasso: yes.** If we divide the coefficient by *c*, then the corresponding penalty term is also divided by *c*.\n",
    "* **Ridge: yes.**. Same as the Lasso method, except we divide the penalty by *c*^2.\n",
    "\n",
    "**Remember that the mean and variance used to scale data are parameters that need to be learned from our training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd33708",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_predictors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m scaler = StandardScaler().fit(train[\u001b[43mall_predictors\u001b[49m])\n\u001b[32m      5\u001b[39m pd.DataFrame({\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m: scaler.mean_,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvariance\u001b[39m\u001b[33m\"\u001b[39m: scaler.var_\n\u001b[32m      8\u001b[39m }, index=all_predictors).T\n",
      "\u001b[31mNameError\u001b[39m: name 'all_predictors' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Only scale the training data\n",
    "scaler = StandardScaler().fit(train[all_predictors])\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"mean\": scaler.mean_,\n",
    "    \"variance\": scaler.var_\n",
    "}, index=all_predictors).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ccff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Scaling in place (not the professor's favorite approach)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m [train, \u001b[43mvalid\u001b[49m, test]:\n\u001b[32m      3\u001b[39m     df[all_predictors] = scaler.transform(df[all_predictors])\n",
      "\u001b[31mNameError\u001b[39m: name 'valid' is not defined"
     ]
    }
   ],
   "source": [
    "# Scaling in place (not the professor's favorite approach)\n",
    "# Probably better to separately assign each scaled data set\n",
    "for df in [train, valid, test]:\n",
    "    df[all_predictors] = scaler.transform(df[all_predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c72e51",
   "metadata": {},
   "source": [
    "# kNN Regression: How Many Neighbors Should we Use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa6b49c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_predictors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m k_vals = [\u001b[32m1\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m15\u001b[39m, \u001b[32m20\u001b[39m, \u001b[32m25\u001b[39m, \u001b[32m30\u001b[39m, \u001b[32m35\u001b[39m, \u001b[32m40\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m60\u001b[39m]\n\u001b[32m      2\u001b[39m knns = {\n\u001b[32m      3\u001b[39m     k: KNeighborsRegressor(n_neighbors=k).fit(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         train[\u001b[43mall_predictors\u001b[49m], train.Fare_amount)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_vals}\n\u001b[32m      7\u001b[39m train_r2s = [\n\u001b[32m      8\u001b[39m     metrics.r2_score(train.Fare_amount, model.predict(train[all_predictors]))\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, model \u001b[38;5;129;01min\u001b[39;00m knns.items()]\n",
      "\u001b[31mNameError\u001b[39m: name 'all_predictors' is not defined"
     ]
    }
   ],
   "source": [
    "k_vals = [1, 5, 10, 15, 20, 25, 30, 35, 40, 50, 60]\n",
    "knns = {\n",
    "    k: KNeighborsRegressor(n_neighbors=k).fit(\n",
    "        train[all_predictors], train.Fare_amount)\n",
    "    for k in k_vals}\n",
    "\n",
    "train_r2s = [\n",
    "    metrics.r2_score(train.Fare_amount, model.predict(train[all_predictors]))\n",
    "    for k, model in knns.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99399ad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_r2s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plt.plot(k_vals, \u001b[43mtrain_r2s\u001b[49m, \u001b[33m'\u001b[39m\u001b[33m-+\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mTrain\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mn_neighbors\u001b[39m\u001b[33m'\u001b[39m)  \n\u001b[32m      3\u001b[39m plt.ylabel(\u001b[33m\"\u001b[39m\u001b[33m$R^2$\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_r2s' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(k_vals, train_r2s, '-+', label=\"Train\")\n",
    "plt.xlabel('n_neighbors')  \n",
    "plt.ylabel(\"$R^2$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb42440",
   "metadata": {},
   "source": [
    "# Validation set is currently unseen\n",
    "\n",
    "So let's see how well our models do on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ca5b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m val_r2s = [\n\u001b[32m      2\u001b[39m     metrics.r2_score(valid.Fare_amount, model.predict(valid[all_predictors]))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mknns\u001b[49m.items()]\n",
      "\u001b[31mNameError\u001b[39m: name 'knns' is not defined"
     ]
    }
   ],
   "source": [
    "val_r2s = [\n",
    "    metrics.r2_score(valid.Fare_amount, model.predict(valid[all_predictors]))\n",
    "    for k, model in knns.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d69730d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_r2s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plt.plot(k_vals, \u001b[43mtrain_r2s\u001b[49m, \u001b[33m'\u001b[39m\u001b[33m-+\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mTrain\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m plt.plot(k_vals, val_r2s, \u001b[33m'\u001b[39m\u001b[33m-*\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mValidation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mn_neighbors\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_r2s' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(k_vals, train_r2s, '-+', label=\"Train\")\n",
    "plt.plot(k_vals, val_r2s, '-*', label=\"Validation\")\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel(\"$R^2$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71ae75",
   "metadata": {},
   "source": [
    "Now which n_neighbors should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43ea5c4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_r2s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_r2_idx = np.argmax(\u001b[43mval_r2s\u001b[49m)\n\u001b[32m      2\u001b[39m best_r2 = val_r2s[best_r2_idx]\n\u001b[32m      3\u001b[39m best_n_neighbors = k_vals[best_r2_idx]\n",
      "\u001b[31mNameError\u001b[39m: name 'val_r2s' is not defined"
     ]
    }
   ],
   "source": [
    "best_r2_idx = np.argmax(val_r2s)\n",
    "best_r2 = val_r2s[best_r2_idx]\n",
    "best_n_neighbors = k_vals[best_r2_idx]\n",
    "print(f\"Best n_neighbors is {best_n_neighbors}, which gives a validation R^2 of {best_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e397b82",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "(From [this resource](https://stats.stackexchange.com/questions/193959/does-cross-validation-on-simple-or-multiple-linear-regression-make-sense))\n",
    "\n",
    "Cross validation and generally validation model techniques are used not only to avoid overfitting (never the case when using linear models) but also when there are different models to compare.\n",
    "\n",
    "A straight last square regression (with no macro-parameters) doesn't get any improvement with cross validation or train-test split that is not obtained by training the model with all the available data!\n",
    "\n",
    "Different is the case if your model is linear but with macro-parameters to choose as Ridge or Lasso regression. In this case using CV validation is a good way to choose the best macro-parameter value , that is the linear model with the best score on the training data\n",
    "\n",
    "Essentially, when you're comparing models, you want to do train/test splits for every model because... you're comparing models! And as for your concerns about scaling, you want to scale the train/test/validation set independently, as each set had their own std and variance and other metrics. If you were to scale all of them using the same scaling parameters, it just wouldn't work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin-reg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
