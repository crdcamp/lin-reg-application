{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818d9149",
   "metadata": {},
   "source": [
    "# Model Selection and Information Criteria\n",
    "\n",
    "Refer to [the slides and other info](https://harvard-iacs.github.io/2018-CS109A/a-sections/a-section-2/). This is a conceptual lesson and does not involve coding. However, I think it'd be wise to apply these concepts from the slides and paper here to be ready for the next section.\n",
    "\n",
    "Let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b5930",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation\n",
    "\n",
    "First thing's first, **likelihood and probability are interrelated, but not synonymous** in the realm of statistics.\n",
    "\n",
    "**Likelihood** refers to how well a sample provides support for particular values of a parameter (theta) in a model.\n",
    "\n",
    "**Probability** refers to the chance that a particular outcome occurs based on the values of parameters in a model.\n",
    "\n",
    "**The critical distinction:**\n",
    "\n",
    "* Probability: P(X=x|θ) treated as a function of x (θ is fixed)\n",
    "* Likelihood: P(X=x|θ) treated as a function of θ (x is fixed/observed)\n",
    "\n",
    "## Statement of the Problem\n",
    "\n",
    "[PSU Resource](https://online.stat.psu.edu/stat415/lesson/1/1.2)\n",
    "\n",
    "Suppose we have a random sample <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>&#x22EF;</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "</math> whose assumed probability distribution depends on some unknown parameter <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>&#x3B8;</mi>\n",
    "</math>. Our primary goal here will be to find a point estimator <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>u</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>&#x22EF;</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>, such that <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>u</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>&#x22EF;</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math> is a \"good\" point estimate of <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>&#x3B8;</mi>\n",
    "</math>, where <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>&#x22EF;</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "</math> are the observed values of the random sample.\n",
    "\n",
    "(Note: Christian had some confusion between PDFs and MLEs below, but is leaving it here just in case.)\n",
    "\n",
    "**Some notes from [this video](https://www.youtube.com/watch?v=k5sbE1_MDwU):** When a random variable is a capital letter (X), we are conveying that this object can take on different values (we haven't observed it yet. It's still random). When we see a lower case (x), we've actually observed a value from the random variable, and it is therefore no longer random.\n",
    "\n",
    "All random variables (X) have a function with\n",
    "1. An input: the random variable and\n",
    "1. An output: how **likely** we are to observe the input number\n",
    "\n",
    "All random variables have such a function that takes the form of either the probability density function (used for continuous random variables) or the probability mass function (discrete random variables). These are both known as **probability distributions**, which tells us about the structure in the randomness.\n",
    "\n",
    "Probabilities for a probability density function (the function we're focused on for this unit's purposes) can come from **point values**, such as f(X = x) or **intervals of values**, f(x1 <= X <= x2).\n",
    "\n",
    "The main idea here is that even though it's impossible to predict values of a random variable ahead of time, **the probability distribution tell us that, over many observations, the *frequency* that they appear will be predictable**. This is what we mean by *structure* - the predictability of the frequency that a random variable will appear despite randomness!\n",
    "\n",
    "To wrap these ideas up: **probability distributions of statistics can tell us what values we are likely or unlikely to observe**.\n",
    "\n",
    "Furthermore, think of it like this: \"The likelihood of theta is how probable the observed data would be if theta had that specific value.\"\n",
    "\n",
    "or \n",
    "\n",
    "\"The likelihood of theta measures how well that value of theta explains the observed data.\"\n",
    "\n",
    "You're not asking about theta \"outputting\" anything or theta being likely. You're asking: \"Assuming theta equals [some specific number], how probable would it have been to see the data I actually saw?\"\n",
    "\n",
    "Now back to the [PSU resource](https://online.stat.psu.edu/stat415/lesson/1/1.2):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c7871",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## The Basic Idea\n",
    "\n",
    "It seems reasonable that a good estimate of the unknown parameter <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>&#x3B8;</mi>\n",
    "</math> would be the value of <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>&#x3B8;</mi>\n",
    "</math> that maximizes the **likelihood** of getting the data we observed. Suppose we have a random sample <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>&#x22EF;</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "</math> for which the PDF of each <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mi>i</mi>\n",
    "  </msub>\n",
    "</math> is <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>f</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>i</mi>\n",
    "  </msub>\n",
    "  <mo>;</mo>\n",
    "  <mi>&#x3B8;</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>. Then, the joint probability mass (or density) function of <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>&#x22EF;</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "</math>, which is called <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>L</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>&#x3B8;</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math> is:\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>L</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>&#x3B8;</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>=</mo>\n",
    "  <mi>P</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>&#x2026;</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>X</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>=</mo>\n",
    "  <mi>f</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>;</mo>\n",
    "  <mi>&#x3B8;</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>&#x22C5;</mo>\n",
    "  <mi>f</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>;</mo>\n",
    "  <mi>&#x3B8;</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>&#x22EF;</mo>\n",
    "  <mi>f</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "  <mo>;</mo>\n",
    "  <mi>&#x3B8;</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>=</mo>\n",
    "  <munderover>\n",
    "    <mo data-mjx-texclass=\"OP\" movablelimits=\"false\">&#x220F;</mo>\n",
    "    <mrow data-mjx-texclass=\"ORD\">\n",
    "      <mi>i</mi>\n",
    "      <mo>=</mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "    <mi>n</mi>\n",
    "  </munderover>\n",
    "  <mi>f</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>i</mi>\n",
    "  </msub>\n",
    "  <mo>;</mo>\n",
    "  <mi>&#x3B8;</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>\n",
    "\n",
    "The The first equality is just the definition of the joint probability mass function. The second equality comes from the fact that we have a random sample, which implies by definition that the Xi are **independent**.\n",
    "\n",
    "In light of the basic idea of maximum likelihood estimation, one reasonable way to proceed is to treat the likelihood function as a function of theta, and find the value of theta that maximizes it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0641e95",
   "metadata": {},
   "source": [
    "## Python Example of MLE\n",
    "\n",
    "[Resource](https://opensourceecon.github.io/CompMethods/struct_est/MLE.html)\n",
    "\n",
    "Each of the model estimation approaches that we will discuss in this section on Maximum Likelihood estimation (MLE) and in subsequent sections on Generalized Method of Moments Estimation (GMM) and Simulated Method of Moments Estimation (SMM) involves choosing values of the parameters of a model to make the model match some number of properties of the data. Define a model or a data generating process (DGP) as,\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <mi>F</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>x</mi>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>z</mi>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mo stretchy=\"false\">|</mo>\n",
    "  </mrow>\n",
    "  <mi>&#x3B8;</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>=</mo>\n",
    "  <mn>0</mn>\n",
    "</math>\n",
    "\n",
    "Theta here is a vector of parameters.\n",
    "\n",
    "The goal of MLE is to choose the parameter vector of the model <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>&#x3B8;</mi>\n",
    "</math> to maximize the likelihood of seeing the data produced by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26270cba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
